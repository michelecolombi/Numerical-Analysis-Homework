{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd956214-1602-4da4-b997-a3abaa704961",
   "metadata": {},
   "source": [
    "# Numerical Optmization Exam\n",
    "Implementation of exercises from Nocedel-Wright."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6e2afc3-3a33-41b9-a1e5-b2528ad476d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcb05fa-d256-4d8b-9ca4-8bb396703459",
   "metadata": {},
   "source": [
    "## Exercise 5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92383edd-3296-4882-8437-c0295368825c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the n×n Hilbert matrix  H_ij = 1/(i+j-1)\n",
    "def hilbert(n):\n",
    "    i = np.arange(1, n + 1)\n",
    "    return 1.0 / (i[:, None] + i[None, :] - 1.0)\n",
    "\n",
    "# Conjugate gradient method (Algorithm 5.2)\n",
    "def cg(A, b, x0, tol, maxit, verbose = False):\n",
    "    \"\"\"Solve  A x = b  with CG.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : SPD matrix (n×n)\n",
    "    b : right‑hand side (n,)\n",
    "    x0 : starting point (defaults to zeros)\n",
    "    tol : stop when  ‖r_k‖ ≤ tol ‖r_0‖\n",
    "    maxit : maximum iterations \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    x      : approximate solution\n",
    "    it     : iterations performed\n",
    "    \"\"\"\n",
    "   \n",
    "    n = b.size\n",
    "    x = x0.copy()\n",
    "\n",
    "    r = A @ x - b           # r0 = A x0 – b \n",
    "    p = -r.copy()           # p0 = -r0\n",
    "    rs_old = r @ r          # r'r\n",
    "\n",
    "    res0 = np.sqrt(rs_old)\n",
    "    history: list[float] = [res0]\n",
    "\n",
    "    for k in range(1, maxit + 1):\n",
    "        alpha = rs_old / (p @ (A @ p))      # (5.24a)\n",
    "        x += alpha * p                      # (5.24b)\n",
    "        r += alpha * (A @ p)                # (5.24c)\n",
    "\n",
    "        rs_new = r @ r\n",
    "        res = np.sqrt(rs_new)\n",
    "        history.append(res)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"k {k} -- res = {res}\")\n",
    "\n",
    "        if res <= tol * res0:\n",
    "            return (x, k) \n",
    "\n",
    "        beta = rs_new / rs_old              # (5.24d)\n",
    "        p = -r + beta * p                   # (5.24e)\n",
    "        \n",
    "        rs_old = rs_new\n",
    "\n",
    "    return (x, maxit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6534389-132f-4fa2-be24-6f3b6c20bd6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n   iterations \n",
      "-   ---------- \n",
      "5       6     \n",
      "8       19    \n",
      "12      37    \n",
      "20      68    \n"
     ]
    }
   ],
   "source": [
    "dims = [5, 8, 12, 20]\n",
    "tol = 1e-6\n",
    "print(\"n   iterations \")\n",
    "print(\"-   ---------- \")\n",
    "\n",
    "for n in dims:\n",
    "    H = hilbert(n)\n",
    "    b = np.ones(n)\n",
    "    x0 = np.zeros(n)\n",
    "\n",
    "    _, it = cg(H, b, x0, tol=tol, maxit=100)\n",
    "    print(f\"{n:<3d} {it:^10d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5048486-c3ee-4366-930b-090bffe4e6ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exercise 14.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa0ac34b-7ab2-4941-a7b1-2e837211f822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mehrotra_lp(A, b, c, max_iter = 10, eta = 0.99, verbose = False):\n",
    "    \n",
    "    m, n = A.shape\n",
    "\n",
    "    # Initialize with large positive values\n",
    "    x   = np.ones(n)\n",
    "    s   = np.ones(n)\n",
    "    lam = np.zeros(m)\n",
    "\n",
    "    e = np.ones(n)\n",
    "\n",
    "    for k in range(max_iter):\n",
    "        r_b = A @ x - b\n",
    "        r_c = A.T @ lam + s - c\n",
    "        mu   = (x @ s) / n\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"iter {k +1:2d}  ‖r_b‖={np.linalg.norm(r_b):.1e}  ‖r_c‖={np.linalg.norm(r_c):.1e}  μ={mu:.1e}\")\n",
    "            \n",
    "\n",
    "        # Predictor step (affine‑scaling step)\n",
    "        X = np.diag(x)\n",
    "        S = np.diag(s)\n",
    "        J = np.block([[np.zeros((n, n)),   A.T,               np.eye(n)],\n",
    "                      [A,                  np.zeros((m, m)),  np.zeros((m, n))],\n",
    "                      [S,                  np.zeros((n, m)),  X],])\n",
    "        rhs_aff = np.concatenate([-r_c, \n",
    "                                  -r_b, \n",
    "                                  -X @ S @ e ])\n",
    "        delta_aff = np.linalg.solve(J, rhs_aff)                                           # (14.30)\n",
    "        dx_aff = delta_aff[:n]\n",
    "        dl_aff = delta_aff[n:n + m]\n",
    "        ds_aff = delta_aff[n + m:]\n",
    "\n",
    "        # Centering step (use affine-scaling step to compute centering parameter)\n",
    "        neg_dx = dx_aff < 0\n",
    "        if np.any(neg_dx):\n",
    "            alpha_aff_pri = min(1.0, np.min(-x[neg_dx] / dx_aff[neg_dx]))                 # (14.32a)\n",
    "\n",
    "        neg_ds = ds_aff < 0\n",
    "        if np.any(neg_ds):\n",
    "            alpha_aff_dua = min(1.0, np.min(-s[neg_ds] / ds_aff[neg_ds]))                 # (14.32b)\n",
    "\n",
    "        mu_aff = ((x + alpha_aff_pri * dx_aff) @ (s + alpha_aff_dua * ds_aff)) / n        # (14.33)\n",
    "        sigma  = (mu_aff / mu) ** 3                                                       # (14.34)\n",
    "\n",
    "        # Corrector step\n",
    "        dX_aff = np.diag(dx_aff)     \n",
    "        dS_aff = np.diag(ds_aff)     \n",
    "        rhs_corr = np.concatenate([-r_c,\n",
    "                                   -r_b,\n",
    "                                   -X @ S @ e - dX_aff @ dS_aff @ e + sigma * mu * e,])    # (14.35)\n",
    "        delta_corr = np.linalg.solve(J, rhs_corr)\n",
    "        dx_corr = delta_corr[:n]\n",
    "        dl_corr = delta_corr[n:n + m]\n",
    "        ds_corr = delta_corr[n + m:]\n",
    "\n",
    "        # Step lengths\n",
    "        neg_dx_corr = dx_corr < 0\n",
    "        if np.any(neg_dx_corr):\n",
    "            alpha_pri = min(1.0, eta*np.min(-x[neg_dx_corr] / dx_corr[neg_dx_corr]))        # (14.38)\n",
    "\n",
    "        neg_ds_corr = ds_corr < 0\n",
    "        if np.any(neg_ds_corr):\n",
    "            alpha_dua = min(1.0, eta*np.min(-s[neg_ds_corr] / ds_corr[neg_ds_corr]))        # (14.38)\n",
    "\n",
    "        # Update \n",
    "        x   += alpha_pri * dx_corr\n",
    "        lam += alpha_dua * dl_corr\n",
    "        s   += alpha_dua * ds_corr\n",
    "\n",
    "    return x, lam, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b21057cd-7057-44e0-961d-4f2840e8fd86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter  1  ‖r_b‖=8.4e+00  ‖r_c‖=1.0e+01  μ=1.0e+00\n",
      "iter  2  ‖r_b‖=8.4e-02  ‖r_c‖=9.5e-02  μ=5.7e-02\n",
      "iter  3  ‖r_b‖=8.4e-04  ‖r_c‖=9.5e-04  μ=5.8e-04\n",
      "iter  4  ‖r_b‖=8.4e-06  ‖r_c‖=9.5e-06  μ=5.8e-06\n",
      "iter  5  ‖r_b‖=8.4e-08  ‖r_c‖=9.5e-08  μ=5.8e-08\n",
      "iter  6  ‖r_b‖=8.4e-10  ‖r_c‖=9.5e-10  μ=5.8e-10\n",
      "iter  7  ‖r_b‖=8.4e-12  ‖r_c‖=9.5e-12  μ=5.8e-12\n",
      "iter  8  ‖r_b‖=8.4e-14  ‖r_c‖=9.6e-14  μ=5.8e-14\n",
      "iter  9  ‖r_b‖=1.1e-15  ‖r_c‖=1.9e-15  μ=6.2e-16\n",
      "iter 10  ‖r_b‖=3.6e-16  ‖r_c‖=1.9e-15  μ=1.6e-17\n",
      "\n",
      "Optimal objective value: 1.3804872504489165\n",
      "Distance to true x     : 2.2790900065266266e-16\n"
     ]
    }
   ],
   "source": [
    "m = 5\n",
    "n = 5\n",
    "l = m + n\n",
    "\n",
    "rng = np.random.default_rng()         \n",
    "A = rng.standard_normal((l, l))\n",
    "\n",
    "x = np.zeros(l)\n",
    "x[:m] = rng.random(m)               \n",
    "\n",
    "s = np.zeros(l)\n",
    "s[m:] = rng.random(n)                  \n",
    "\n",
    "lam = rng.standard_normal(l)\n",
    "\n",
    "c = A.T @ lam + s\n",
    "b = A @ x\n",
    "\n",
    "x_opt, lam_opt, s_opt = mehrotra_lp(A, b, c, verbose=True)\n",
    "print(\"\\nOptimal objective value:\", c @ x_opt)\n",
    "print(\"Distance to true x     :\", np.linalg.norm(x_opt - x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3732d30d-d04e-4375-87ef-197278c99d0f",
   "metadata": {},
   "source": [
    "## Exercise 17.3\n",
    "We will implement the Newton method for the unconstrained optmization, assuming unit-length steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17582c01-2308-441b-a39d-9b18ec854615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_unconstrained(f, grad, hess, x0, tol, max_it=100):\n",
    "    x = x0.copy()\n",
    "    for _ in range(max_it):\n",
    "        g = grad(x)\n",
    "        if np.linalg.norm(g) < tol:\n",
    "            break\n",
    "        p = -np.linalg.solve(hess(x), g)\n",
    "        x += p                     \n",
    "    return x\n",
    "\n",
    "def penalty_minimisation():\n",
    "    x0 = np.array([2.0, 0.0])      \n",
    "    history = []\n",
    "\n",
    "    for k, mu in enumerate([1, 10, 100, 1000], start=1):\n",
    "        def Q(x):\n",
    "            g = x[0]**2 + x[1]**2 - 2\n",
    "            return x.sum() + 0.5*mu*g**2\n",
    "\n",
    "        def grad_Q(x):\n",
    "            g = x[0]**2 + x[1]**2 - 2\n",
    "            return np.array([\n",
    "                1 + 2*mu*g*x[0],\n",
    "                1 + 2*mu*g*x[1],\n",
    "            ])\n",
    "\n",
    "        def hess_Q(x):\n",
    "            x1, x2 = x\n",
    "            g = x1**2 + x2**2 - 2\n",
    "            return np.array([\n",
    "                [2*mu*(3*x1**2 + x2**2 - 2), 4*mu*x1*x2],\n",
    "                [4*mu*x1*x2, 2*mu*(3*x2**2 + x1**2 - 2)],\n",
    "            ])\n",
    "\n",
    "        tau = 1.0 / mu\n",
    "        x0  = newton_unconstrained(Q, grad_Q, hess_Q, x0, tol=tau)\n",
    "        history.append(x0.copy())\n",
    "        print(f\"µ={mu:4d}   x≈{x0},   ‖∇Q‖={np.linalg.norm(grad_Q(x0)):.2e}\")\n",
    "\n",
    "    return np.vstack(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a0153f5-b830-4ad8-abe7-2e619eb557f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "µ=   1   x≈[-0.66504064 -1.47614495],   ‖∇Q‖=8.52e-01\n",
      "µ=  10   x≈[-1.00937068 -1.0160636 ],   ‖∇Q‖=5.30e-02\n",
      "µ= 100   x≈[-1.00085259 -1.00164937],   ‖∇Q‖=3.89e-03\n",
      "µ=1000   x≈[-1.00011968 -1.0001304 ],   ‖∇Q‖=7.04e-04\n",
      "\n",
      "Sequence of minimisers:\n",
      " [[-0.66504064 -1.47614495]\n",
      " [-1.00937068 -1.0160636 ]\n",
      " [-1.00085259 -1.00164937]\n",
      " [-1.00011968 -1.0001304 ]]\n"
     ]
    }
   ],
   "source": [
    "res = penalty_minimisation()\n",
    "print(\"\\nSequence of minimisers:\\n\", res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
